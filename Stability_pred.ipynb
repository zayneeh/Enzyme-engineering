{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1uaukDDDWL5YGOFqSjri_FY-nL6DjRewy",
      "authorship_tag": "ABX9TyNTSAZchS6zo3C8d7YtBlbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zayneeh/Enzyme-engineering/blob/main/Stability_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "BdUKeMLh5emH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWqBBkiRQwKL",
        "outputId": "2aa8ddfa-9c5a-4a0e-e119-18bb7858ae43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch biopython pandas\n",
        "!pip install fair-esm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qY6_HCoV_Kt",
        "outputId": "e070168c-89db-4629-8d04-71dc6f0d72c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jafetgado/tomer.git\n",
        "%cd tomer\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uu_txnazcpR",
        "outputId": "47d4073f-d7fb-451e-9c60-067ebc6034c6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tomer'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 117 (delta 58), reused 91 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (117/117), 1.76 MiB | 6.52 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "/content/tomer\n",
            "Collecting numpy<1.20,>=1.19 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas<0.25,>=0.24.1 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-0.24.2.tar.gz (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating tomer.egg-info\n",
            "writing tomer.egg-info/PKG-INFO\n",
            "writing dependency_links to tomer.egg-info/dependency_links.txt\n",
            "writing requirements to tomer.egg-info/requires.txt\n",
            "writing top-level names to tomer.egg-info/top_level.txt\n",
            "writing manifest file 'tomer.egg-info/SOURCES.txt'\n",
            "reading manifest file 'tomer.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'tomer.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib/tomer\n",
            "copying tomer/resreg.py -> build/lib/tomer\n",
            "copying tomer/tomer.py -> build/lib/tomer\n",
            "copying tomer/__init__.py -> build/lib/tomer\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'tomer.data' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'tomer.data' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'tomer.data' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'tomer.data' to be distributed and are\n",
            "        already explicitly excluding 'tomer.data' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "creating build/lib/tomer/data\n",
            "copying tomer/data/sequence_ogt_topt.csv -> build/lib/tomer/data\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/tomer\n",
            "copying build/lib/tomer/resreg.py -> build/bdist.linux-x86_64/egg/tomer\n",
            "copying build/lib/tomer/tomer.py -> build/bdist.linux-x86_64/egg/tomer\n",
            "copying build/lib/tomer/__init__.py -> build/bdist.linux-x86_64/egg/tomer\n",
            "creating build/bdist.linux-x86_64/egg/tomer/data\n",
            "copying build/lib/tomer/data/sequence_ogt_topt.csv -> build/bdist.linux-x86_64/egg/tomer/data\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tomer/resreg.py to resreg.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tomer/tomer.py to tomer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tomer/__init__.py to __init__.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tomer.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tomer.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tomer.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tomer.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying tomer.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "tomer.__pycache__.tomer.cpython-311: module references __file__\n",
            "creating dist\n",
            "creating 'dist/tomer-1.0-py3.11.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing tomer-1.0-py3.11.egg\n",
            "creating /usr/local/lib/python3.11/dist-packages/tomer-1.0-py3.11.egg\n",
            "Extracting tomer-1.0-py3.11.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding tomer 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/tomer-1.0-py3.11.egg\n",
            "Processing dependencies for tomer==1.0\n",
            "Searching for scikit-learn==1.6.1\n",
            "Best match: scikit-learn 1.6.1\n",
            "Adding scikit-learn 1.6.1 to easy-install.pth file\n",
            "detected new path './tomer-1.0-py3.11.egg'\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for scipy==1.15.3\n",
            "Best match: scipy 1.15.3\n",
            "Adding scipy 1.15.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pandas==2.2.2\n",
            "Best match: pandas 2.2.2\n",
            "Adding pandas 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for numpy==2.0.2\n",
            "Best match: numpy 2.0.2\n",
            "Adding numpy 2.0.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing numpy-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for threadpoolctl==3.6.0\n",
            "Best match: threadpoolctl 3.6.0\n",
            "Adding threadpoolctl 3.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for joblib==1.5.1\n",
            "Best match: joblib 1.5.1\n",
            "Adding joblib 1.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tzdata==2025.2\n",
            "Best match: tzdata 2025.2\n",
            "Adding tzdata 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pytz==2025.2\n",
            "Best match: pytz 2025.2\n",
            "Adding pytz 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dateutil==2.9.0.post0\n",
            "Best match: python-dateutil 2.9.0.post0\n",
            "Adding python-dateutil 2.9.0.post0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for six==1.17.0\n",
            "Best match: six 1.17.0\n",
            "Adding six 1.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for tomer==1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n"
      ],
      "metadata": {
        "id": "m-BwRZBNRnLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read fasta alignment of the chosen enzymes Q5U780 and P82597 from uniprot.\n"
      ],
      "metadata": {
        "id": "13k9DD7h55D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_fasta_alignment(filename):\n",
        "    seqs = {}\n",
        "    current_key = None\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\">\"):\n",
        "                current_key = line\n",
        "                seqs[current_key] = \"\"\n",
        "            elif line:\n",
        "                seqs[current_key] += line\n",
        "    return seqs\n",
        "\n",
        "# Usage\n",
        "alignment = read_fasta_alignment(\"/content/drive/MyDrive/Enzyme Pred/alignment.fasta\")\n",
        "\n",
        "# To view the sequences:\n",
        "for name, seq in alignment.items():\n",
        "    print(name)\n",
        "    print(seq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eWrmfVcQKs4",
        "outputId": "b51d72f2-1307-4f0a-e5d8-d45366282930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">sp|P82597|MGLP_BAC25\n",
            "---------MSEQY-----PVLSGA-EPFYAENGPVGVLLVHGFTGTPHSMRPLAEAYAKAGYTVCLPRLKGHGTHYEDMERTTFHDWVASVEEGYGWLKQRCQTIFVTG----------------LSMGGTLTLYLAEHHPDICGIVPINAAVDIPAIAAGMTGGGELPRYLDSIGS--------DLKNPDVKELAYEKTPTASLLQLARLMAQTKAKLDRIVCPALIFVSDEDHVVPPGNADIIFQGISSTEK------E-----IVRLRNSYHVATLDY--DQPMII---ERSLE-FFAKHAG--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            ">sp|Q5U780|LIP_BACSP\n",
            "MKCCRIMFVLLGLWFVFGLSVPGGRTEAASLRANDAPIVLLHGFTGWGRE------------------------------EMFGFKYWGGVRGDIEQWLNDNGYRTYTLAVGPLSSNWDRACEAYAQLVGGTVDYG-AAH-AAKHGHAR--FGRTYPGLLPELKRGGRIHIIAHSQGGQTARMLVSLLENGSQEEREYAKAHNVSLSPLF--------------EGGHHFVLSVTTIATPHDGTTLVNMVDFTDRFFDLQKAVLEAAAVASNVPYTSQVYDFKLDQWGLRRQPGESFDHYFERLKRSPVWTSTDTARYDLSVSGAEKLNQWVQASPNTYYLSFSTERTYRGALTGNHYPELGMNAFSAVVCAPFLGSYRNPTLGIDDRWLENDGIVNTVSMNGPKRGSSDRIVPYDGTLKKGVWNDMGTYNVDHLEIIGVDPNPSFDIRAFYLRLAEQLASLRP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# Let's make sure order is preserved\n",
        "alignment = OrderedDict(alignment)\n",
        "\n",
        "seq_names = list(alignment.keys())\n",
        "seq1 = alignment[seq_names[0]]\n",
        "seq2 = alignment[seq_names[1]]\n",
        "\n",
        "variable_positions = []\n",
        "for i, (aa1, aa2) in enumerate(zip(seq1, seq2)):\n",
        "    if aa1 != aa2 and aa1 != '-' and aa2 != '-':\n",
        "        variable_positions.append(i)\n",
        "print(\"Variable positions:\", variable_positions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGYjxriXQVbM",
        "outputId": "31355367-9d40-4222-9d0c-bb4aca61fcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable positions: [9, 10, 11, 12, 13, 19, 21, 22, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 46, 47, 48, 49, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 126, 127, 128, 132, 133, 134, 135, 138, 141, 142, 143, 144, 146, 147, 148, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 170, 171, 172, 173, 175, 177, 186, 188, 190, 191, 192, 193, 195, 196, 198, 200, 201, 202, 203, 206, 207, 209, 224, 225, 226, 227, 228, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 261, 267, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 281, 286, 287, 288, 289, 293, 294, 296, 297, 299, 301, 302, 303, 304, 305]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\""
      ],
      "metadata": {
        "id": "6Y6YAgKlRsg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_fasta_alignment(filename):\n",
        "    records = list(SeqIO.parse(filename, \"fasta\"))\n",
        "    if len(records) < 2:\n",
        "        raise ValueError(\"Alignment must contain at least two sequences.\")\n",
        "    return records"
      ],
      "metadata": {
        "id": "W5VbwJRjRtom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alignment = read_fasta_alignment(\"/content/drive/MyDrive/Enzyme Pred/alignment.fasta\")\n",
        "seq1 = str(alignment[0].seq)\n",
        "seq2 = str(alignment[1].seq)\n",
        "seq2_no_gaps = seq2.replace(\"-\", \"\")"
      ],
      "metadata": {
        "id": "Nt_OxSIqRvxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Find variable positions in alignment"
      ],
      "metadata": {
        "id": "ezNL8kNA7Z34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "variable_positions = []\n",
        "align_to_seq_idx = {}\n",
        "seq_idx = 0\n",
        "for i, (aa1, aa2) in enumerate(zip(seq1, seq2)):\n",
        "    if aa2 != \"-\":\n",
        "        align_to_seq_idx[i] = seq_idx\n",
        "        seq_idx += 1\n",
        "    # Only mutate where both sequences have a residue\n",
        "    if aa1 != aa2 and aa1 != '-' and aa2 != '-':\n",
        "        variable_positions.append(i)"
      ],
      "metadata": {
        "id": "BlZgEpP8R1M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Generate mutants"
      ],
      "metadata": {
        "id": "NteW50d97X3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mutants = []\n",
        "for pos in variable_positions:\n",
        "    wt_aa = seq2[pos]\n",
        "    seq_pos = align_to_seq_idx.get(pos)\n",
        "    if wt_aa == \"-\" or seq_pos is None:\n",
        "        continue\n",
        "    for aa in amino_acids:\n",
        "        if aa != wt_aa:\n",
        "            mutant_seq = list(seq2_no_gaps)\n",
        "            mutant_seq[seq_pos] = aa\n",
        "            mutant_seq_str = \"\".join(mutant_seq)\n",
        "            # FASTA header: indicate mutation, e.g. Q5U780_A123V\n",
        "            header = f\">Q5U780_{wt_aa}{seq_pos+1}{aa}\"\n",
        "            mutants.append(SeqRecord(Seq(mutant_seq_str), id=header, description=\"\"))\n"
      ],
      "metadata": {
        "id": "ok5H_MKYQq-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Write mutants to FASTA file"
      ],
      "metadata": {
        "id": "BfoaDMaF6bWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"/content/mutants.fasta\", \"w\") as out_f:\n",
        "    SeqIO.write(mutants, out_f, \"fasta\")\n",
        "\n",
        "print(f\"{len(mutants)} mutants written to mutants.fasta\")"
      ],
      "metadata": {
        "id": "OfjCW1rLR8Ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af71b16-df5d-4256-a82a-6356f7d1860b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3002 mutants written to mutants.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_seqs = sum(1 for _ in SeqIO.parse('/content/mutants.fasta', 'fasta'))\n",
        "with open('/content/ogts.txt', 'w') as f:\n",
        "    f.write('OGT\\n')   # <-- Header row\n",
        "    for _ in range(num_seqs):\n",
        "        f.write('70\\n')\n"
      ],
      "metadata": {
        "id": "rcKTD2G3TXGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict Topt of the mutants using Tomer"
      ],
      "metadata": {
        "id": "Vaj0zO6R6eeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tomer\n",
        "df = tomer.pred_fasta_topt('/content/mutants.fasta','/content/ogts.txt' )\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaqTWuYOSbBx",
        "outputId": "d230a808-740d-487f-e4fb-e0ba14ec30b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                ID    Topt   Std err\n",
            "0      Q5U780_L10A    77.5  1.417921\n",
            "1      Q5U780_L10C   78.03  1.422424\n",
            "2      Q5U780_L10D   77.83  1.414217\n",
            "3      Q5U780_L10E   77.75    1.4124\n",
            "4      Q5U780_L10F   77.76   1.39908\n",
            "...            ...     ...       ...\n",
            "2997  Q5U780_R258S  77.295   1.47328\n",
            "2998  Q5U780_R258T  77.245  1.469804\n",
            "2999  Q5U780_R258V  77.205  1.458665\n",
            "3000  Q5U780_R258W   77.14  1.498801\n",
            "3001  Q5U780_R258Y   78.52  1.440728\n",
            "\n",
            "[3002 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the mutants with the highest Topt"
      ],
      "metadata": {
        "id": "5KREHFBo6lF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_candidates = df.sort_values('Topt', ascending=False)\n",
        "print(top_candidates.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF7JQCEnWLhi",
        "outputId": "6e434760-9e1f-4043-be04-5f3ca747bd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                ID   Topt   Std err\n",
            "1659  Q5U780_G144I  79.42  1.270723\n",
            "44     Q5U780_G12I  79.42  1.270723\n",
            "2344  Q5U780_V199I  79.42  1.356369\n",
            "1907  Q5U780_V170I  79.42  1.356369\n",
            "614    Q5U780_G60I  79.42  1.270723\n",
            "2686  Q5U780_V231I  79.42  1.356369\n",
            "1299  Q5U780_R120I  79.42  1.296046\n",
            "254    Q5U780_R32I  79.42  1.296046\n",
            "1279  Q5U780_G119I  79.42  1.270723\n",
            "2477  Q5U780_R207I  79.42  1.296046\n",
            "595    Q5U780_G59I  79.42  1.270723\n",
            "2267  Q5U780_G195I  79.42  1.270723\n",
            "1014   Q5U780_V99I  79.42  1.356369\n",
            "1242  Q5U780_R117I  79.42  1.296046\n",
            "2001  Q5U780_G178I  79.42  1.270723\n",
            "2020  Q5U780_G179I  79.42  1.270723\n",
            "1033  Q5U780_V103I  79.42  1.356369\n",
            "443    Q5U780_G48I  79.42  1.270723\n",
            "634    Q5U780_V61I  79.42  1.356369\n",
            "653    Q5U780_R62I  79.42  1.296046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_ids = set(top_candidates['ID'][:20])"
      ],
      "metadata": {
        "id": "TFCRvCh9XMhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the mutants with the highest topt**"
      ],
      "metadata": {
        "id": "5AiBmppO64Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_fasta = '/content/mutants.fasta'\n",
        "output_fasta = '/content/top_mutants.fasta'\n",
        "\n",
        "# Add \">\" to each DataFrame ID to match the FASTA IDs\n",
        "top_ids = set('>' + i.strip() for i in top_candidates['ID'][:20])\n",
        "\n",
        "top_records = [rec for rec in SeqIO.parse(input_fasta, 'fasta') if rec.id in top_ids]\n",
        "\n",
        "print(f\"Found {len(top_records)} top sequences.\")\n",
        "\n",
        "SeqIO.write(top_records, output_fasta, 'fasta')\n",
        "print(f\"Saved {len(top_records)} records to {output_fasta}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8pi08Q1WWz1",
        "outputId": "56bc553e-a29d-4c1e-d3cc-65445d4781c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 top sequences.\n",
            "Saved 20 records to /content/top_mutants.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precting the Topt of the enzyme using ESM"
      ],
      "metadata": {
        "id": "xsfu37ca6_Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fair-esm biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmxpGWsiTdfR",
        "outputId": "14897890-4ae9-450c-e47b-d82b24843dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fair-esm in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "import torch\n",
        "import esm\n",
        "import numpy as np\n",
        "\n",
        "# Load ESM-2\n",
        "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model.eval()\n",
        "\n",
        "# Load your FASTA sequences\n",
        "sequences = [(record.id, str(record.seq)) for record in SeqIO.parse(\"/content/drive/MyDrive/Enzyme Pred/mutants.fasta\", \"fasta\")]\n",
        "\n",
        "def get_esm_embeddings(seq_list, batch_size=8):\n",
        "    all_embeds = []\n",
        "    for i in range(0, len(seq_list), batch_size):\n",
        "        batch = seq_list[i:i+batch_size]\n",
        "        batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
        "        with torch.no_grad():\n",
        "            results = model(batch_tokens, repr_layers=[6])\n",
        "        reps = results[\"representations\"][6]\n",
        "        for j, (_, seq) in enumerate(batch):\n",
        "            all_embeds.append(reps[j, 1:len(seq)+1].mean(0).cpu().numpy())\n",
        "    return np.stack(all_embeds)\n",
        "\n",
        "X_variants = get_esm_embeddings(sequences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uMjiBIodZRHC",
        "outputId": "0f378f43-9f49-41ae-868c-54128d5e0570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-1113542919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mesm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2220\u001b[0m \u001b[0;31m# quantization depends on torch.fx and torch.ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[0;31m# Import quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2222\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mquantization\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2224\u001b[0m \u001b[0;31m# Import the quasi random sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mypy: allow-untyped-defs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfake_quantize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuse_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfuser_method_mappings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/quantization/fake_quantize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from torch.ao.quantization.fake_quantize import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0m_is_fake_quant_script_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0m_is_per_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfuser_method_mappings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from .pt2e._numeric_debugger import (  # noqa: F401\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcompare_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mCUSTOM_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/pt2e/_numeric_debugger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_sqnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt2e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_control_flow_submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportedProgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecomp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomDecompTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdynamic_shapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShapesCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m from .exported_program import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/export/decomp_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from torch._export.utils import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_collect_all_valid_cia_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_collect_all_valid_cia_ops_for_aten_namespace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_PyTreeCodeGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PyTreeInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_wrap_submodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_materialize_cpp_cia_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Example: Load a CSV with columns 'sequence' and 'tm'\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Enzyme Pred/train.csv\")\n",
        "train_sequences = [(f\"train{i}\", seq) for i, seq in enumerate(train_df['protein_sequence'])]\n",
        "X_train = get_esm_embeddings(train_sequences)\n",
        "y_train = train_df['tm'].values\n",
        "\n",
        "# Train the model\n",
        "reg = Ridge().fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mh-1Nt0PUbwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_pred = reg.predict(X_variants)"
      ],
      "metadata": {
        "id": "uVe-Cvh3abv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "for rec, pred_tm in zip(seq_records, tm_pred):\n",
        "    results.append({\n",
        "        'id': rec.id,\n",
        "        'sequence': str(rec.seq),\n",
        "        'predicted_tm': pred_tm\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(\"all_predicted_tm.csv\", index=False)"
      ],
      "metadata": {
        "id": "v9mGe3unc3Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top mutants with highest Tm\n",
        "N = 30\n",
        "top_df = df_results.sort_values(by='predicted_tm', ascending=False).head(N)"
      ],
      "metadata": {
        "id": "jAM1bQWJc6IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as FASTA\n",
        "top_seqs = []\n",
        "id_to_seq = {rec.id: rec for rec in seq_records}\n",
        "for idx, row in top_df.iterrows():\n",
        "    rec = id_to_seq[row['id']]\n",
        "    # Update description to include predicted Tm (optional)\n",
        "    rec.description = f\"predicted_tm={row['predicted_tm']:.2f}\"\n",
        "    top_seqs.append(rec)\n",
        "\n",
        "SeqIO.write(top_seqs, \"top_mutants.fasta\", \"fasta\")\n",
        "\n",
        "print(f\"Saved top {N} mutants with highest predicted Tm to 'top_mutants.fasta'.\")\n",
        "print(\"All predictions saved to 'all_predicted_tm.csv'.\")\n"
      ],
      "metadata": {
        "id": "kPotKPGhcxmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the folding and structure of the top variants using Alphafold https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/batch/AlphaFold2_batch.ipynb**"
      ],
      "metadata": {
        "id": "vXRb21j2CI0o"
      }
    }
  ]
}